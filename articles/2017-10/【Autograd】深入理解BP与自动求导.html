<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>
	
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="baidu-site-verification" content="o4pXUBsPyW" />
	
    <!--Description-->
    
        <meta name="description" content="To be more curious and less lazy.">
    

    <!--Author-->
    
        <meta name="author" content="Chen Dian">
    

    <!--Open Graph Title-->
    
        <meta property="og:title" content="【Autograd】深入理解BP与自动求导"/>
    

    <!--Open Graph Description-->
    
        <meta property="og:description" content="To be more curious and less lazy." />
    

    <!--Open Graph Site Name-->
    <meta property="og:site_name" content="CDPlayer&#39;s Blog"/>

    <!--Type page-->
    
        <meta property="og:type" content="article" />
    

    <!--Page Cover-->
    

    <meta name="twitter:card" content="summary" />
    

    <!-- Title -->
    
    <title>【Autograd】深入理解BP与自动求导 - CDPlayer&#39;s Blog</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/4.0.0-alpha.2/css/bootstrap.min.css" integrity="sha384-y3tfxAZXuh4HwSYylfB+J125MxIs6mR5FOHamPBG064zB+AFeWH94NdvaCBm8qnd" crossorigin="anonymous">

    <!-- Custom Fonts -->
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Gallery -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.css" type="text/css" rel="stylesheet" />

    <!-- Custom CSS -->
    <link rel="stylesheet" href="../../css/style.css">

    <!-- Google Analytics -->
    

	
	<!-- Baidu Analytics -->
    
	<script type="text/javascript">
		var _hmt = _hmt || [];
		(function() {
		  var hm = document.createElement("script");
		  hm.src = "https://hm.baidu.com/hm.js?{{ theme.baidu_analytics }}";
		  var s = document.getElementsByTagName("script")[0];
		  s.parentNode.insertBefore(hm, s);
		})();
	</script>


	
	<!-- star map -->
	<script type="text/javascript" color="255,255,255" opacity='0.75' zIndex="-2" count="88" src="js/canvas.js"></script>
	
	<!-- Earth -->
	<script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=5mihyim0z76&amp;m=7&amp;c=66ccff&amp;cr1=ff0000&amp;f=arial&amp;l=0&amp;lx=200&amp;ly=-20&amp;hi=10" async="async"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>


<body>

<!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="bg-gradient"></div>
<div class="bg-pattern"></div>

<!-- Menu -->
<!--Menu Links and Overlay-->
<div class="menu-bg">
    <div class="menu-container">
        <ul>
            
            <li class="menu-item">
                <a href="../../index.html">
                    Home
                </a>
            </li>
            
            <li class="menu-item">
                <a href="../../tags">
                    Tags
                </a>
            </li>
            
            <li class="menu-item">
                <a href="../../archives">
                    Archives
                </a>
            </li>
            
            <li class="menu-item">
                <a href="../../categories">
                    Categories
                </a>
            </li>
            
            <li class="menu-item">
                <a href="../../about">
                    About
                </a>
            </li>
            
        </ul>
    </div>
</div>

<!--Hamburger Icon-->
<nav>
    <a href="#menu"></a>
</nav>

<div class="container">

    <!-- Main Content -->
    <div class="row">
    <div class="col-sm-12">

        <!--Title and Logo-->
        <header>
    <div class="logo">
        <a href="/"><i class="logo-icon fa fa-cube" aria-hidden="true"></i></a>
        
    </div>
</header>

        <section class="main">
            
<div class="post">

    <div class="post-header">
        <h1 class="title">
            <a href="../../articles/2017-10/【Autograd】深入理解BP与自动求导.html">
                【Autograd】深入理解BP与自动求导
            </a>
        </h1>
        <div class="post-info">
            
                <span class="date">2017-10-18</span>
            
            
                <a href="#disqus_thread" class="comments">留言</a>
            
            
                <span class="category">
                    <a href="/categories/机器学习/">机器学习</a>
                </span>
            
        </div>
    </div>

    <div class="content">

        <!-- Gallery -->
        

		<!-- MathJax support -->
		
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
	tex2jax: {
	  inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
	  processEscapes: true,
	  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
	}
  });
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
	var all = MathJax.Hub.getAllJax(), i;
	for (i=0; i < all.length; i += 1) {
	  all[i].SourceElement().parentNode.className += ' has-jax';
	}
  });
</script>

<script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML">
</script>



		
        <!-- Post Content -->
        <h3 id="符号语言的导数"><a href="#符号语言的导数" class="headerlink" title="符号语言的导数"></a>符号语言的导数</h3><blockquote>
<p>《Deep Learning》 Chap 6.5.5</p>
</blockquote>
<p><img src="/assets/1508315592269.png" alt="Alt text"></p>
<p>代数表达式和计算图都对符号(symbol) 或不具有特定值的变量进行操作。这些代数或者基于图的表达式被称为符号表示(symbolic representation)。<br>当我们实际使用或者训练神经网络时，我们必须给这些符号赋值。我们用一个特定的数值(numeric value) 来替代网络的符号输入x，例如 $[1.2, 3, 765, -􀀀1.8]^T$。</p>
<a id="more"></a>
<p><strong>符号到数值</strong>的微分<br>一些反向传播的方法采用计算图和一组用于图的输入的数值，然后返回在这些输入值处梯度的一组数值。我们将这种方法称为‘‘符号到数值’’ 的微分。这种方法用在诸如<strong>Torch</strong>(Collobert et al., 2011b)和<strong>Caffe</strong>(Jia, 2013)之类的库中。  </p>
<p><strong>符号到符号</strong>的微分<br>另一种方法是采用计算图以及添加一些额外的节点到计算图中，这些额外的节点提供了我们所需导数的符号描述。这是<strong>Theano</strong>(Bergstra et al., 2010b; Bastien et al., 2012b) 和<strong>TensorFlow</strong>(Abadi et al., 2015) 采用的方法。图6.10给出了该方法如何工作的一个例子。这种方法的主要优点是导数可以使用与原始表达式相同的语言来描述。因为导数只是另外一张计算图，可以再次运行反向传播，对导数再进行求导以得到更高阶的导数。（这里我们重点讲这一种）</p>
<p><img src="/assets/1508315628313.png" alt="Alt text"></p>
<h3 id="Backpropagation-algorithm"><a href="#Backpropagation-algorithm" class="headerlink" title="Backpropagation algorithm"></a>Backpropagation algorithm</h3><blockquote>
<p><a href="http://neuralnetworksanddeeplearning.com/chap2.html" target="_blank" rel="external">http://neuralnetworksanddeeplearning.com/chap2.html</a><br><img src="/assets/1508321998322.png" alt="Alt text"></p>
</blockquote>
<h3 id="Jacobi与链式法则"><a href="#Jacobi与链式法则" class="headerlink" title="Jacobi与链式法则"></a>Jacobi与链式法则</h3><blockquote>
<p>《Deep Learning》 Chap 6.5.2</p>
</blockquote>
<p>微积分中的链式法则（为了不与概率中的链式法则相混淆）用于计算复合函数的导数。反向传播是一种计算链式法则的算法，使用高效的特定运算顺序。<br>设 $x$ 是实数， $f$ 和 $g$ 是从实数映射到实数的函数。假设 $y = g(x)$ 并且 $z =f(g(x)) = f(y)$ 。那么链式法则是说</p>
<script type="math/tex; mode=display">\frac{dz}{dx}=\frac{dz}{dy} \frac{dy}{dx}</script><p>我们可以将这种标量情况进行扩展。 假设$ x\in \mathbb{R}^m, y\in \mathbb{R}^n$，$g$是从$\mathbb{R}^m$到$\mathbb{R}^n$的映射，$f$是从$\mathbb{R}^n$到$\mathbb{R}$的映射。 如果$ y=g(x)$并且$z=f(y)$，那么</p>
<script type="math/tex; mode=display">\frac{\partial z}{\partial x_i} = \sum_j \frac{\partial z}{\partial y_j} \frac{\partial y_j}{\partial x_i}.</script><p>使用向量记法，可以等价地写成</p>
<script type="math/tex; mode=display">\nabla_{x}z = \left ( \frac{\partial y}{\partial x} \right )^\top \nabla_{y} z,</script><p>通常我们不将反向传播算法仅用于向量，而是应用于任意维度的张量。从概念上讲，这与使用向量的反向传播完全相同。唯一的区别是如何将数字排列成网格以形成张量。<br>我们可以想象，在我们运行反向传播之前，将每个张量变平为一个向量，计算一个向量值梯度，然后将该梯度重新构造成一个张量。从这种重新排列的观点上看，反向传播仍然只是将 $Jacobi$ 矩阵乘以梯度。</p>
<p>如果 $Y=g(X)$ 并且 $z=f(Y)$，那么 </p>
<script type="math/tex; mode=display">\nabla_X z = \sum_j (\nabla_X Y_j)\frac{\partial z}{\partial Y_j}.</script><p>于是，反向传播算法就变得非常简单：<br>为了计算某个标量 $z$ 关于图中它的一个祖先 $x$ 的梯度，我们首先观察到它关于 $z$ 的梯度由 $\frac{dz}{dz}=1$ 给出。 然后，我们可以计算对图中 $z$ 的每个父节点的梯度，通过现有的梯度乘以产生$z$的操作的 $Jacobian$。 我们继续乘以 $Jacobian$，以这种方式向后穿过图，直到我们到达 $x$。 对于从 $z$ 出发可以经过两个或更多路径向后行进而到达的任意节点，我们简单地对该节点来自不同路径上的梯度进行求和。</p>
<p><img src="/assets/1508318743867.png" alt="Alt text"></p>
<h3 id="自动求导实现"><a href="#自动求导实现" class="headerlink" title="自动求导实现"></a>自动求导实现</h3><p>采用如下子程序来建立 $grad_table$：<br><img src="/assets/1508319803477.png" alt="Alt text"></p>
<p>每个操作 $op$ 也与 $bprop$ 操作相关联。该 $bprop$ 操作可以计算如上述公式所描述的 $Jacobi$ 向量积。这是反向传播算法能够实现很大通用性的原因。每个操作负责了解如何通过它参与的图中的边来反向传播。反向传播算法本身并<strong>不需要</strong>知道任何微分法则。它只需要使用正确的参数调用每个操作的 $bprop$ 方法即可。正式地，$op.bprop(inputs,X,G)$ 必须返回</p>
<script type="math/tex; mode=display">\sum_i (\nabla_{X} \verb|op.f(inputs|)_i) \textsf{G}_i,</script><p>这里，$inputs$ 是提供给操作的一组输入，$op.f$ 是操作实现的数学函数，$X$ 是输入，我们想要计算关于它的梯度，$G$ 是操作对于输出的梯度。</p>
<blockquote>
<p>$op.bprop$ 方法应该总是假装它的所有输入彼此不同，即使它们不是。例如，如果 $mul$ 操作传递两个 $x$ 来计算 $x^2$，$op.bprop$ 方法应该仍然返回 $x$ 作为对于两个输入的导数。反向传播算法后面会将这些变量加起来获得 $2x$，这是 $x$ 上总的正确的导数。</p>
<p>反向传播算法的软件实现通常提供操作和其 $bprop$ 两种方法，所以深度学习软件库的用户能够对使用诸如矩阵乘法、指数运算、对数运算等等常用操作构建的图进行反向传播。构建反向传播新实现的软件工程师或者需要向现有库添加自己的操作的高级用户通常必须手动为新操作推导 $op.bprop$ 方法。</p>
</blockquote>
<p>由于重复子表达式的存在，简单的算法可能具有指数运行时间。现在我们已经详细说明了反向传播算法，我们可以去理解它的计算成本：<br>对于与 $Theano$ 与 $Tensorflow$ 类似的平台，反向传播算法在原始图的每条边添加一个 $Jacobi$ 向量积，可以用 $O(1)$ 个节点来表达。因为计算图是有向无环图，它至多有 $O(n^2)$ 条边。<br>而对于实践中常用的图的类型，情况会更好：大多数神经网络的代价函数大致是链式结构的，使得反向传播只有 $O(n)$ 的成本。这远远胜过简单的方法，简单方法可能需要执行指数级的节点。这种潜在的指数级代价可以通过非递归地扩展和重写递归链式法则看出：</p>
<script type="math/tex; mode=display">\frac{\partial u^{(n)}}{\partial u^{(j)}} =
  \sum_{\substack{\text{path}(u^{(\pi_1)}, u^{(\pi_2)}, \ldots, u^{(\pi_t)}  ),\ \text{from } \pi_1=j \text{ to }\pi_t = n}}
  \prod_{k=2}^t \frac{\partial u^{(\pi_k)}}{\partial u^{(\pi_{k-1})}}.</script><p>由于节点 $j$ 到节点 $n$ 的路径数目可以关于这些路径的长度上指数地增长，所以上述求和符号中的项数（这些路径的数目），可能以前向传播图的深度的指数级增长。 会产生如此大的成本是因为对于 $\frac{\partial u^{(i)}}{\partial u^{(j)}}$ ，相同的计算会重复进行很多次。 为了避免这种重新计算，我们可以将反向传播看作一种表填充算法，利用存储的中间结果 $\frac{\partial u^{(n)}}{\partial u^{(i)}}$ 来对表进行填充。 图中的每个节点对应着表中的一个位置，这个位置存储对该节点的梯度。 通过顺序填充这些表的条目，反向传播算法避免了重复计算许多公共子表达式——这种表填充策略有时被称为<strong>动态规划</strong>。</p>
<h3 id="高阶导数"><a href="#高阶导数" class="headerlink" title="高阶导数"></a>高阶导数</h3><p>一些软件框架支持使用高阶导数。在深度学习软件框架中，这至少包括Theano和TensorFlow。这些库使用一种数据结构来描述要被微分的原始函数，它们使用相同类型的数据结构来描述这个函数的导数表达式。这意味着符号微分机制可以应用于导数（从而产生高阶导数）。</p>
<blockquote>
<p>黑塞矩阵（Hessian Matrix），又译作海森矩阵、海瑟矩阵、海塞矩阵等，是一个多元函数的二阶偏导数构成的方阵，描述了函数的局部曲率。黑塞矩阵最早于19世纪由德国数学家Ludwig Otto Hesse提出，并以其名字命名。黑塞矩阵常用于牛顿法解决优化问题，利用黑塞矩阵可判定多元函数的极值问题。</p>
</blockquote>
<p>在深度学习的相关领域，很少会计算标量函数的单个二阶导数。 相反，我们通常对Hessian矩阵的性质比较感兴趣。 如果我们有函数 $f:\mathbb{R}^n \to \mathbb{R}$，那么Hessian矩阵的大小是 $n\times n$。 在典型的深度学习应用中，$n$ 将是模型的参数数量，可能很容易达到数十亿。 因此，完整的Hessian矩阵甚至不能表示。</p>
<p>典型的深度学习方法是使用Krylov方法，而不是显式地计算Hessian矩阵。 Krylov方法是用于执行各种操作的一组迭代技术，这些操作包括像近似求解矩阵的逆、或者近似矩阵的特征值或特征向量等，而不使用矩阵-向量乘法以外的任何操作。</p>
<p>为了在Hesssian矩阵上使用Krylov方法，我们只需要能够计算Hessian矩阵 $H$ 和一个任意向量 $v$ 间的乘积即可（该表达式中两个梯度的计算都可以由适当的软件库自动完成）：</p>
<script type="math/tex; mode=display">H v=\nabla_{x} \left [ (\nabla_{x} f(x))^\top v\right ]</script><p>虽然计算Hessian通常是不可取的，但是可以使用Hessian向量积。 可以对所有的 $i=1,\ldots,n$ 简单地计算 $H e^{(i)}$，其中 $e^{(i)}$ 是 $e_i^{(i)}=1$ 并且其他元素都为 $0$ 的one-hot向量。</p>
<h3 id="How-autograd-encodes-the-history-PyTorch"><a href="#How-autograd-encodes-the-history-PyTorch" class="headerlink" title="How autograd encodes the history (PyTorch)"></a>How autograd encodes the history (PyTorch)</h3><blockquote>
<p><a href="http://pytorch.org/docs/master/notes/autograd.html#how-autograd-encodes-the-history" target="_blank" rel="external">http://pytorch.org/docs/master/notes/autograd.html#how-autograd-encodes-the-history</a></p>
</blockquote>
<p>Autograd is reverse automatic differentiation system. Conceptually, autograd records a graph recording all of the operations that created the data as you execute operations, giving you a directed acyclic graph whose leaves are the input variables and roots are the output variables. By tracing this graph from roots to leaves, you can automatically compute the gradients using the chain rule.</p>
<p>Internally, autograd represents this graph as a graph of <code>Function</code> objects (really expressions), which can be <code>apply()</code> ed to compute the result of evaluating the graph. When computing the forwards pass, autograd <strong>simultaneously performs</strong> the requested computations and builds up <strong>a graph representing the function that computes the gradient</strong> (the <code>.grad_fn</code> attribute of each <code>Variable</code> is <strong>an entry point</strong> into this graph). When the forwards pass is completed, we evaluate this graph in the backwards pass to compute the gradients.</p>
<p>An important thing to note is that the graph is recreated from scratch at every iteration, and this is exactly what allows for using arbitrary Python control flow statements, that can change the overall shape and size of the graph at every iteration. You don’t have to encode all possible paths before you launch the training - what you run is what you differentiate.</p>

    </div>

    

    
        <div class="post-tags">
            <i class="fa fa-tags" aria-hidden="true"></i>
            <a href="/tags/Backpropagation/">#Backpropagation</a> <a href="/tags/Autograd/">#Autograd</a>
        </div>
    

    <!-- Comments -->
    
    <div class="comments">
        
<div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>



    </div>
    

</div>
        </section>

    </div>
</div>

</div>

<!-- Footer -->
<div class="push"></div>

<footer class="footer-content">
    <div class="container">
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-6 col-lg-6 footer-about">
                <h2>About</h2>
                <p>
                    Coding the world, try to fetch more.
                </p>
                <script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=5mihyim0z76&amp;m=7&amp;c=66ccff&amp;cr1=ff0000&amp;f=arial&amp;l=0&amp;lx=200&amp;ly=-20&amp;hi=10" async="async"></script>
            </div>
            
    <div class="col-xs-6 col-sm-6 col-md-3 col-lg-3 recent-posts">
        <h2>Recent Posts</h2>
        <ul>
            
            <li>
                <a class="footer-post" href="../../articles/2017-10/【Autograd】深入理解BP与自动求导.html">【Autograd】深入理解BP与自动求导</a>
            </li>
            
            <li>
                <a class="footer-post" href="../../articles/2017-10/【Codeforces】33th_Codeforces_Contest.html">【Codeforces】33th_Codeforces_Contest</a>
            </li>
            
            <li>
                <a class="footer-post" href="../../articles/2017-10/【Chrome-crx】键盘模拟鼠标点击网页按钮.html">【Chrome-Crx】键盘模拟鼠标点击网页按钮</a>
            </li>
            
            <li>
                <a class="footer-post" href="../../articles/2017-10/【Pytorch】Torch_NN_Learning.html">【Pytorch】Torch_NN_Learning</a>
            </li>
            
        </ul>
    </div>



            
<div class="col-xs-6 col-sm-6 col-md-3 col-lg-3 footer-categories">
    <h2>Categories</h2>
    <ul>
        
        <li>
            <a class="footer-post" href="../../categories/解题报告/">解题报告</a>
        </li>
        
        <li>
            <a class="footer-post" href="../../categories/论文阅读/">论文阅读</a>
        </li>
        
        <li>
            <a class="footer-post" href="../../categories/机器学习/">机器学习</a>
        </li>
        
        <li>
            <a class="footer-post" href="../../categories/编程记忆/">编程记忆</a>
        </li>
        
        <li>
            <a class="footer-post" href="../../categories/环境配置/">环境配置</a>
        </li>
        
        <li>
            <a class="footer-post" href="../../categories/功能脚本/">功能脚本</a>
        </li>
        
    </ul>
</div>

        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <ul class="list-inline footer-social-icons">
                    
                    <li class="list-inline-item">
                        <a href="https://github.com/okcd00/">
                            <span class="footer-icon-container">
                                <i class="fa fa-github"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="https://twitter.com/okcd00/">
                            <span class="footer-icon-container">
                                <i class="fa fa-twitter"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    
                    
                    
                    <li class="list-inline-item">
                        <a href="http://okcd00.oschina.io/">
                            <span class="footer-icon-container">
                                <i class="fa fa-star-half-o"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="mailto:okcd00@vip.qq.com">
                            <span class="footer-icon-container">
                                <i class="fa fa-envelope-o"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    <li class="list-inline-item">
                        <a href="http://blog.csdn.net/okcd00">
                            <span class="footer-icon-container">
                                <i class="fa fa-pencil-square-o"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                </ul>
            </div>
        </div>
        <div class="row">
            <div class="col-xs-12 col-sm-12 col-md-12 col-lg-12">
                <div class="footer-copyright">
                    @<a href="https://github.com/okcd00/">Dian Chen</a>. 2017 All right reserved | Redesign & Deploy <a href="blog.csdn.net/okcd00">okcd00</a> | Hexo Theme <a href="http://www.codeblocq.com/">Jonathan Klughertz</a>
                </div>
            </div>
        </div>
    </div>
</footer>

<!-- After footer scripts -->

<!-- jQuery -->
<script src="//code.jquery.com/jquery-2.1.4.min.js"></script>

<!-- Tween Max -->
<script src="//cdnjs.cloudflare.com/ajax/libs/gsap/1.18.5/TweenMax.min.js"></script>

<!-- Gallery -->
<script src="//cdnjs.cloudflare.com/ajax/libs/featherlight/1.3.5/featherlight.min.js" type="text/javascript" charset="utf-8"></script>

<!-- Custom JavaScript -->
<script src="../../js/main.js"></script>

<!-- Disqus Comments -->

<script type="text/javascript">
    var disqus_shortname = 'okcd00';

    (function(){
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<!-- "//cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js" -->
<script type="text/javascript" color="0,255,255" opacity='0.75' zIndex="-2" count="75" src='/js/canvas.js'></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>