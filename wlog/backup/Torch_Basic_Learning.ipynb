{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch \n",
    "+ Tensor computation (like numpy) with strong GPU acceleration\n",
    "+ PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.\n",
    "+ It has a CUDA counterpart, that enables you to run your tensor computations on an NVIDIA GPU with compute capability >= 3.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import success.\n",
      "Torch Version:0.2.1+a4fc05a\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "print(\"Import success.\\nTorch Version:{}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Package|Description|\n",
    "|:------|---------:|\n",
    "|torch|a Tensor library like NumPy, with strong GPU support|\n",
    "|torch.autograd|a tape based automatic differentiation library that supports all differentiable Tensor operations in torch|\n",
    "|torch.nn|a neural networks library deeply integrated with autograd designed for maximum flexibility|\n",
    "|torch.optim|an optimization package to be used with torch.nn with standard optimization methods such as SGD, RMSProp, LBFGS, Adam etc.|\n",
    "|torch.multiprocessing|python multiprocessing, but with magical memory sharing of torch Tensors across processes. Useful for data loading and hogwild training.|\n",
    "|torch.utils|DataLoader, Trainer and other utility functions for convenience|\n",
    "|torch.legacy(.nn/.optim)|legacy code that has been ported over from torch for backward compatibility reasons|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief view in pytorch\n",
    "``` python\n",
    "torch.set_printoptions(\n",
    "    precision=None, # Number of digits of precision for floating point output (default 8).\n",
    "    threshold=None, # Total number of array elements which trigger summarization rather than full repr (default 1000).\n",
    "    edgeitems=None, # Number of array items in summary at beginning and end of each dimension (default 3).\n",
    "    linewidth=None, # The number of characters per line for the purpose of inserting line breaks (default 80). \n",
    "                    # Thresholded matricies will ignore this parameter.\n",
    "    profile=None,   # Sane defaults for pretty printing. Can override with any of the above options. (default, short, full) \n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Matrix:\n",
      " [[[[-1.26951553 -0.5783194  -0.2817905  -1.91081633]\n",
      "   [-1.03255087  0.09356858  0.87141257  0.24527875]\n",
      "   [-1.57634325 -0.95006681 -0.54418479 -0.81721992]]\n",
      "\n",
      "  [[ 1.52620998  1.19114026  0.12362855  0.30176001]\n",
      "   [-0.18951867  0.33470665 -1.13370011  1.17999206]\n",
      "   [ 0.17942397 -0.15441461  0.53326092 -0.22955392]]]]\n",
      "\n",
      "Torch Matrix: \n",
      "(0 ,0 ,.,.) = \n",
      "  1.6238  0.4029 -1.6028  0.4393\n",
      "  0.0485 -0.5608 -1.3842  1.6696\n",
      "  0.9837  0.7565 -0.8661 -0.6509\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      " -0.3699 -0.8046  0.3459  0.3806\n",
      "  0.0225 -0.0216  0.5001  0.4924\n",
      "  0.2519 -1.1100 -1.5480 -0.0549\n",
      "[torch.FloatTensor of size 1x2x3x4]\n",
      "\n",
      "\n",
      "Torch Matrix: \n",
      "(0 ,0 ,.,.) = \n",
      " 1.62381 0.40293 -1.60275 0.43934\n",
      " 0.04847 -0.56078 -1.38419 1.66964\n",
      " 0.98369 0.75650 -0.86610 -0.65095\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      " -0.36994 -0.80465 0.34593 0.38057\n",
      " 0.02247 -0.02161 0.50013 0.49238\n",
      " 0.25189 -1.10998 -1.54797 -0.05489\n",
      "[torch.FloatTensor of size 1x2x3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np_mat = np.random.randn(1,2,3,4)\n",
    "tc_mat = torch.randn(1,2,3,4)\n",
    "print(\"Numpy Matrix:\\n\", np_mat)\n",
    "print(\"\\nTorch Matrix:\", tc_mat)\n",
    "\n",
    "torch.set_printoptions(precision=5) # change print options, just link numpy\n",
    "print(\"\\nTorch Matrix:\", tc_mat)\n",
    "torch.set_printoptions(profile='default') # back to default_pretty_printing\n",
    "# print(\"\\nTorch Matrix:\", tc_mat) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy defination and assignment with numpy\n",
    "+ torch.from_numpy(<type numpy.array>) creates a Tensor from a numpy.ndarray.\n",
    "\n",
    "> The returned tensor and ndarray **share the same memory**. Modifications to the tensor will be reflected in the ndarray and vice versa. \n",
    "> The returned tensor is **not resizable**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Matrix:\n",
      " [[[[ 0.28134406 -0.34748676  0.83155334  0.85618986]\n",
      "   [-0.95961146 -0.68374939 -1.67800331  0.84947823]\n",
      "   [-0.72478517  0.71535117 -2.02988345 -0.1911564 ]]\n",
      "\n",
      "  [[ 1.04884339  0.35382358 -0.69535152  0.27244267]\n",
      "   [-0.18157492 -0.02892887 -0.54348221  1.49079913]\n",
      "   [ 0.6273026   0.86512992 -1.02024843 -0.58441433]]]]\n",
      "Torch matrix from Numpy:\n",
      " \n",
      "(0 ,0 ,.,.) = \n",
      "  0.2813 -0.3475  0.8316  0.8562\n",
      " -0.9596 -0.6837 -1.6780  0.8495\n",
      " -0.7248  0.7154 -2.0299 -0.1912\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      "  1.0488  0.3538 -0.6954  0.2724\n",
      " -0.1816 -0.0289 -0.5435  1.4908\n",
      "  0.6273  0.8651 -1.0202 -0.5844\n",
      "[torch.DoubleTensor of size 1x2x3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tc_mat = torch.from_numpy(np_mat)\n",
    "print(\"Numpy Matrix:\\n\", np_mat)\n",
    "print(\"\\nTorch matrix from Numpy:\", tc_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "+ torch.clamp(x, min, max)\n",
    "+ torch.cat((x, x, ..., x), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix a: \n",
      "-0.0708  0.7695  0.4194 -0.2349\n",
      "-1.6515  0.4604  0.7691  0.3826\n",
      "-0.7259 -0.0289 -0.7962  0.5046\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      "After torch.clamp: \n",
      "-0.0708  0.5000  0.4194 -0.2349\n",
      "-0.5000  0.4604  0.5000  0.3826\n",
      "-0.5000 -0.0289 -0.5000  0.5000\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      "After torch.cat((a,a), axis=1): \n",
      "-0.0708  0.7695  0.4194 -0.2349 -0.0708  0.7695  0.4194 -0.2349\n",
      "-1.6515  0.4604  0.7691  0.3826 -1.6515  0.4604  0.7691  0.3826\n",
      "-0.7259 -0.0289 -0.7962  0.5046 -0.7259 -0.0289 -0.7962  0.5046\n",
      "[torch.FloatTensor of size 3x8]\n",
      "\n",
      "\n",
      "After torch.cat((a,a,a), axis=0): \n",
      "-0.0708  0.7695  0.4194 -0.2349\n",
      "-1.6515  0.4604  0.7691  0.3826\n",
      "-0.7259 -0.0289 -0.7962  0.5046\n",
      "-0.0708  0.7695  0.4194 -0.2349\n",
      "-1.6515  0.4604  0.7691  0.3826\n",
      "-0.7259 -0.0289 -0.7962  0.5046\n",
      "-0.0708  0.7695  0.4194 -0.2349\n",
      "-1.6515  0.4604  0.7691  0.3826\n",
      "-0.7259 -0.0289 -0.7962  0.5046\n",
      "[torch.FloatTensor of size 9x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3,4)\n",
    "print('Original Matrix a:', a)\n",
    "print('\\nAfter torch.clamp:', torch.clamp(a, min=-0.5, max=0.5))\n",
    "\n",
    "cat0, cat1 = torch.cat((a, a, a), 0), torch.cat((a, a), 1)\n",
    "print('\\nAfter torch.cat((a,a), axis=1):', cat1)\n",
    "print('\\nAfter torch.cat((a,a,a), axis=0):', cat0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Select\n",
    "+ torch.masked_select\n",
    "+ torch.index_select\n",
    "> Returned Tensor does not use the same storage as the original Tensor  \n",
    "> and `masked_select returns a 1-dim tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix a: \n",
      "-0.0708  0.7695  0.4194 -0.2349\n",
      "-1.6515  0.4604  0.7691  0.3826\n",
      "-0.7259 -0.0289 -0.7962  0.5046\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "\n",
      "Mask for greater_than_0.5: \n",
      " 0  1  0  0\n",
      " 0  0  1  0\n",
      " 0  0  0  1\n",
      "[torch.ByteTensor of size 3x4]\n",
      "\n",
      "\n",
      "After torch.masked_select(a, mask): \n",
      " 0.7695\n",
      " 0.7691\n",
      " 0.5046\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "We select index: select = torch.LongTensor([0, 2])\n",
      "\n",
      "After torch.index_select(a, axis=0, select): \n",
      "-0.0708  0.7695  0.4194 -0.2349\n",
      "-0.7259 -0.0289 -0.7962  0.5046\n",
      "[torch.FloatTensor of size 2x4]\n",
      "\n",
      "\n",
      "After torch.index_select(a, axis=1, select): \n",
      "-0.0708  0.4194\n",
      "-1.6515  0.7691\n",
      "-0.7259 -0.7962\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "select = torch.LongTensor([0, 2])\n",
    "sel0 = torch.index_select(a, 0, select)\n",
    "sel1 = torch.index_select(a, 1, select)\n",
    "print('Original Matrix a:', a)\n",
    "\n",
    "mask = a.gt(0.5) # if element is greater than 0.5\n",
    "print('\\nMask for greater_than_0.5:', mask)\n",
    "print('\\nAfter torch.masked_select(a, mask):', torch.masked_select(a, mask))\n",
    "\n",
    "print('We select index: select = torch.LongTensor([0, 2])')\n",
    "print('\\nAfter torch.index_select(a, axis=0, select):', sel0)\n",
    "print('\\nAfter torch.index_select(a, axis=1, select):', sel1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Squeeze\n",
    "+ torch.squeeze\n",
    "\n",
    "> You can select which axis to be squeezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Z:                 \t  torch.Size([4, 5, 1, 2])\n",
      "Size of Z after squeeze(z):\t  torch.Size([4, 5, 2])\n",
      "Size of Z after squeeze(z, 1):\t  torch.Size([4, 5, 1, 2])\n",
      "Size of Z after squeeze(z, 2):\t  torch.Size([4, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "z = torch.zeros(4,5,1,2)\n",
    "print(\"Size of Z:                 \\t \", z.size())\n",
    "print(\"Size of Z after squeeze(z):\\t \", torch.squeeze(z).size())\n",
    "print(\"Size of Z after squeeze(z, 1):\\t \", torch.squeeze(z, 1).size())\n",
    "print(\"Size of Z after squeeze(z, 2):\\t \", torch.squeeze(z, 2).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [Serialization](http://pytorch.org/docs/master/notes/serialization.html#recommend-saving-models)\n",
    "+ [Parallelism](http://pytorch.org/docs/master/torch.html#parallelism)\n",
    "    + torch.`set_num_threads(int)`\n",
    "    + torch.`get_num_threads()` → int\n",
    "+ Check Matrix Comparison\n",
    "    + torch.`eq()`/`ge()`/`gt()` -> Tensor\n",
    "    + torch.`equal()` -> Bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-place random sampling\n",
    "There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation:\n",
    "\n",
    "|Distribution|description|\n",
    "|:------|---------:|\n",
    "| `torch.Tensor.bernoulli_()`| in-place version of torch.bernoulli() |\n",
    "| `torch.Tensor.cauchy_()` | numbers drawn from the Cauchy distribution |\n",
    "| `torch.Tensor.exponential_()` | numbers drawn from the exponential distribution |\n",
    "| `torch.Tensor.geometric_()` | elements drawn from the geometric distribution |\n",
    "| `torch.Tensor.log_normal_()` | samples from the log-normal distribution |\n",
    "| `torch.Tensor.normal_()` | in-place version of torch.normal() |\n",
    "| `torch.Tensor.random_()` | numbers sampled from the discrete uniform distribution |\n",
    "| `torch.Tensor.uniform_()` | numbers sampled from the uniform distribution |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Variable for requires_grad or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable a=x+y requires grad:  False\n",
      "Variable b=a+z requires grad:  True\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "# http://pytorch.org/docs/master/autograd.html#torch.autograd.Function\n",
    "x = Variable(torch.randn(5, 5))\n",
    "y = Variable(torch.randn(5, 5))\n",
    "z = Variable(torch.randn(5, 5), requires_grad=True)\n",
    "a = x + y\n",
    "b = a + z\n",
    "print(\"Variable a=x+y requires grad: \", a.requires_grad)\n",
    "print(\"Variable b=a+z requires grad: \", b.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Finished Basic\n",
    "I can't wait for Machine learning!       \n",
    "Let's start new learning into [torch.nn](http://pytorch.org/docs/master/nn.html)~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dynamic_graph](http://pytorch.org/static/img/dynamic_graph.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.1(Torch)",
   "language": "python",
   "name": "python361"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
